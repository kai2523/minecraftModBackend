{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b042426",
   "metadata": {},
   "source": [
    "## Finetuning des TinyBERT Modells auf die label freundlich, neutral und unfreundlich mit Hilfe des zuvor generierten Datensatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a18c37",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a44d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7fbeec",
   "metadata": {},
   "source": [
    "### Umgebungsvariablen setzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c505275",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"dvm1983/TinyBERT_General_4L_312D_de\"\n",
    "dataset_path = \"sentences_cleaned.csv\"\n",
    "label_list = [\"unfreundlich\",\"neutral\",\"freundlich\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fee612",
   "metadata": {},
   "source": [
    "### CSV laden und Train-Test-Split des Datensatzes durchf√ºhren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"csv\", data_files=dataset_path, split=\"train\")\n",
    "ds = ds.train_test_split(test_size=0.2, seed=42)\n",
    "train_ds, eval_ds = ds[\"train\"], ds[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45701fa9",
   "metadata": {},
   "source": [
    "### Neue Labels mappen und Originalspalte droppen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6333f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id   = {lab:i for i,lab in enumerate(label_list)}\n",
    "id2label   = {i:lab for lab,i in label2id.items()}\n",
    "\n",
    "def map_labels(ex):\n",
    "    return {\"labels\": label2id[ex[\"label\"]]}\n",
    "\n",
    "train_ds = train_ds.map(map_labels, remove_columns=[\"label\"])\n",
    "eval_ds  = eval_ds.map(map_labels, remove_columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aa1022",
   "metadata": {},
   "source": [
    "### Tokenizer laden und Texte tokenizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b807bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "def tokenize_fn(ex):\n",
    "    return tokenizer(\n",
    "        ex[\"sentence\"], padding=\"max_length\", truncation=True, max_length=128\n",
    "    )\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[\"sentence\"])\n",
    "eval_ds  = eval_ds.map(tokenize_fn, batched=True, remove_columns=[\"sentence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e53abc",
   "metadata": {},
   "source": [
    "### Data collator f√ºr dynamisches Padding, damit alle Batches rechteckige Tensors sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2904adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7873140b",
   "metadata": {},
   "source": [
    "### Format f√ºr PyTorch-Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6776d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "eval_ds.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369e30cf",
   "metadata": {},
   "source": [
    "### Modell laden und Classification Head neu initialisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c579518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dvm1983/TinyBERT_General_4L_312D_de and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(label_list),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969c235e",
   "metadata": {},
   "source": [
    "### Trainingparameter f√ºr das Finetuning setzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1560: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ü§ó Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.05,\n",
    "    warmup_ratio=0.2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=250,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=250,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    report_to=[\"none\"],\n",
    "    dataloader_num_workers=0,\n",
    "    no_cuda=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4c0e63",
   "metadata": {},
   "source": [
    "### Metrics-Funktion zum Entpacken der Tuple in p.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d00902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds  = np.argmax(logits, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(p.label_ids, preds)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3946cc47",
   "metadata": {},
   "source": [
    "### Trainer initialisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef5e11c",
   "metadata": {},
   "source": [
    "### Batch-Shape-Debug pr√ºfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69675c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-Shapes: {'labels': torch.Size([16]), 'input_ids': torch.Size([16, 128]), 'attention_mask': torch.Size([16, 128])}\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(trainer.get_train_dataloader()))\n",
    "print(\"Batch-Shapes:\", {k: v.shape for k,v in batch.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddf8e8a",
   "metadata": {},
   "source": [
    "### Training starten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2deeb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1377d7a3ff2f4c808234063da89579d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1758 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ce2692b3974d1b83b0504c3e12ef12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4258507192134857, 'eval_accuracy': 0.9397693293464332, 'eval_runtime': 105.0811, 'eval_samples_per_second': 22.278, 'eval_steps_per_second': 0.704, 'epoch': 0.43}\n",
      "{'loss': 0.5812, 'grad_norm': 5.0923991203308105, 'learning_rate': 1.7894736842105264e-05, 'epoch': 0.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a5e32ed1b442a993aee21e6b9d2b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11504026502370834, 'eval_accuracy': 0.9773601025202905, 'eval_runtime': 102.0835, 'eval_samples_per_second': 22.932, 'eval_steps_per_second': 0.725, 'epoch': 0.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653834935f08416c9849751678676c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06530832499265671, 'eval_accuracy': 0.9850491243058522, 'eval_runtime': 95.9329, 'eval_samples_per_second': 24.402, 'eval_steps_per_second': 0.771, 'epoch': 1.28}\n",
      "{'loss': 0.0777, 'grad_norm': 29.406478881835938, 'learning_rate': 1.0782361308677099e-05, 'epoch': 1.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae1511cc48c4482b668fde00f0f2951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0502033568918705, 'eval_accuracy': 0.9884664673216574, 'eval_runtime': 105.8039, 'eval_samples_per_second': 22.126, 'eval_steps_per_second': 0.699, 'epoch': 1.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f38a28b26b4c97ab4cdb62be810f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04191646724939346, 'eval_accuracy': 0.9910294745835113, 'eval_runtime': 109.9916, 'eval_samples_per_second': 21.283, 'eval_steps_per_second': 0.673, 'epoch': 2.13}\n",
      "{'loss': 0.045, 'grad_norm': 0.11010090261697769, 'learning_rate': 3.669985775248933e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7167444145874a0898d52d790e31c541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04453492537140846, 'eval_accuracy': 0.9897479709525844, 'eval_runtime': 102.5108, 'eval_samples_per_second': 22.837, 'eval_steps_per_second': 0.722, 'epoch': 2.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08010a83f4a4a669897492666abbd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03899088874459267, 'eval_accuracy': 0.9918838103374626, 'eval_runtime': 98.2029, 'eval_samples_per_second': 23.838, 'eval_steps_per_second': 0.754, 'epoch': 2.99}\n",
      "{'train_runtime': 1272.5217, 'train_samples_per_second': 22.069, 'train_steps_per_second': 1.382, 'train_loss': 0.20711825677830475, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1758, training_loss=0.20711825677830475, metrics={'train_runtime': 1272.5217, 'train_samples_per_second': 22.069, 'train_steps_per_second': 1.382, 'total_flos': 100677258443520.0, 'train_loss': 0.20711825677830475, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327c9b1a",
   "metadata": {},
   "source": [
    "### Modell speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d4c7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fertig! Modell liegt in ./tinybert-german-finetuned\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"tinybert-german-finetuned\")\n",
    "print(\"Fertig! Modell liegt in ./tinybert-german-finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981404b4",
   "metadata": {},
   "source": [
    "## Nun soll das gefintunete Modell gegen das urspr√ºngliche Modell evaluiert werden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5e753f",
   "metadata": {},
   "source": [
    "### Set an Test-S√§tzen definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d40e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    # freundlich\n",
    "    {\"sentence\": \"Du bist so toll und hilfst mir immer!\",               \"label\": \"freundlich\"},\n",
    "    {\"sentence\": \"Hallo lieber Dorfbewohner, k√∂nnte man preislich bei dir noch was machen? Ich kann dir 2 Rohes Kaninchen f√ºr einen Smaragd geben. Das w√§re wirklich freundlich und ich w√ºrde mich echt freuen\",        \"label\": \"freundlich\"},\n",
    "    {\"sentence\": \"Ich freue mich auf unsere Zusammenarbeit.\",          \"label\": \"freundlich\"},\n",
    "    {\"sentence\": \"Dein Engagement wird sehr gesch√§tzt.\",              \"label\": \"freundlich\"},\n",
    "    {\"sentence\": \"Herzlichen Gl√ºckwunsch zu deinem gro√üartigen Erfolg!\", \"label\": \"freundlich\"},\n",
    "\n",
    "    # neutral\n",
    "    {\"sentence\": \"Kann man preislich bei dir noch was machen? Ich kann dir 2 Rohes Kaninchen f√ºr einen Smaragd geben.\",           \"label\": \"neutral\"},\n",
    "    {\"sentence\": \"Wie crafte ich eine Diamantspitzhacke?\",  \"label\": \"neutral\"},\n",
    "    {\"sentence\": \"Das Wald-Biom hat viele Eichenb√§ume.\",         \"label\": \"neutral\"},\n",
    "    {\"sentence\": \"Unsere n√§chste Station ist die Mine zum Erze farmen.\",       \"label\": \"neutral\"},\n",
    "    {\"sentence\": \"Das Wetter soll morgen bew√∂lkt sein.\",          \"label\": \"neutral\"},\n",
    "\n",
    "    # unfreundlich\n",
    "    {\"sentence\": \"Was f√ºr ein Idiot bist du bitte?\",                   \"label\": \"unfreundlich\"},\n",
    "    {\"sentence\": \"Willst du stress du Arschloch?\",          \"label\": \"unfreundlich\"},\n",
    "    {\"sentence\": \"Hey du Arschloch, was kostet eine d√§mliche Karte bei dir?\",                  \"label\": \"unfreundlich\"},\n",
    "    {\"sentence\": \"Halte endlich dein Maul.\",                \"label\": \"unfreundlich\"},\n",
    "    {\"sentence\": \"Komm raus ich hau dich!\",   \"label\": \"unfreundlich\"},\n",
    "    {\"sentence\": \"Du Spast, wie ist das Wetter?\",                \"label\": \"unfreundlich\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a6dd18",
   "metadata": {},
   "source": [
    "### Test-Dataset erzeugen und Labels mappen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8acb17cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f81f54060d14fbea91310bc97343775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_list = [\"unfreundlich\", \"neutral\", \"freundlich\"]\n",
    "label2id   = {lab:i for i,lab in enumerate(label_list)}\n",
    "id2label   = {i:lab for lab,i in label2id.items()}\n",
    "\n",
    "# 2) Dataset erzeugen und Labels mappen\n",
    "test_ds = Dataset.from_list(test_data)\n",
    "test_ds = test_ds.map(lambda ex: {\"labels\": label2id[ex[\"label\"]]}, remove_columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1792cfb4",
   "metadata": {},
   "source": [
    "### Tokenizer & Tokenisierung f√ºr das Original-TinyBERT-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b187988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6800bfc182db4ceb82f7633e05ca1eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"dvm1983/TinyBERT_General_4L_312D_de\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "def tokenize_fn(ex):\n",
    "    return tokenizer(ex[\"sentence\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "test_ds = test_ds.map(tokenize_fn, batched=True, remove_columns=[\"sentence\"])\n",
    "test_ds.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc12355",
   "metadata": {},
   "source": [
    "### Funktionen zur Evaluation definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e5dbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    \"\"\"\n",
    "    Berechnet die Accuracy basierend auf den Modellvorhersagen und den wahren Labels.\n",
    "\n",
    "    Args: p: Ein Objekt mit den Attributen\n",
    "           - predictions (np.ndarray): Die Vorhersagen des Modells.\n",
    "           - label_ids (np.ndarray): Die wahren Label-IDs.\n",
    "\n",
    "    Returns: dict: Ein Dictionary mit dem Key \"accuracy\" und dem zugeh√∂rigen Value als float.\n",
    "    \"\"\"\n",
    "    logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds  = np.argmax(logits, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(p.label_ids, preds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccc228a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_path: str, name: str):\n",
    "    \"\"\"\n",
    "    L√§dt ein Sentiment-Modell, wertet es auf dem Testdatensatz aus\n",
    "    und gibt sowohl Einzelergebnisse als auch einen Bericht zur Gesamtleistung aus.\n",
    "\n",
    "    Args: model_path (str): Pfad zum Modellverzeichnis.\n",
    "          name (str): Bezeichner f√ºr die aktuelle Evaluation\n",
    "\n",
    "    Returns: None (Ausgabe der Evaluationsergebnisse in der Konsole)\n",
    "    \"\"\"\n",
    "    print(f\"Evaluation: {name}\")\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Modell laden\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_path,\n",
    "        num_labels=len(label_list),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    ).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Dataloader\n",
    "    test_loader = DataLoader(test_ds, batch_size=16)\n",
    "\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            preds = torch.argmax(probs, dim=-1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Originaldaten f√ºr Anzeige\n",
    "    sentences = [ex[\"sentence\"] for ex in test_data]\n",
    "\n",
    "    # Anzeige\n",
    "    print(\"\\nEinzelne Predictions:\")\n",
    "    for i, (sent, true_id, pred_id, prob_row) in enumerate(zip(sentences, all_labels, all_preds, all_probs)):\n",
    "        print(f\"{i+1:2d}. ‚Äû{sent}‚Äú\")\n",
    "        print(f\"Label: {id2label[true_id]:11s},\"\n",
    "              f\" Vorhersage: {id2label[pred_id]:11s},\"\n",
    "              f\" Confidence: {prob_row[pred_id]:.2f}\")\n",
    "\n",
    "    # Gesamtbewertung\n",
    "    print(\"\\nGesamtbewertung:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ea46ce",
   "metadata": {},
   "source": [
    "### Vergeleich des Original TinyBERT Modells gegen das gefintunte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27eb8345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: Original_TinyBERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dvm1983/TinyBERT_General_4L_312D_de and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Einzelne Predictions:\n",
      " 1. ‚ÄûDu bist so toll und hilfst mir immer!‚Äú\n",
      "Label: freundlich , Vorhersage: neutral    , Confidence: 0.36\n",
      " 2. ‚ÄûHallo lieber Dorfbewohner, k√∂nnte man preislich bei dir noch was machen? Ich kann dir 2 Rohes Kaninchen f√ºr einen Smaragd geben. Das w√§re wirklich freundlich und ich w√ºrde mich echt freuen‚Äú\n",
      "Label: freundlich , Vorhersage: neutral    , Confidence: 0.35\n",
      " 3. ‚ÄûIch freue mich auf unsere Zusammenarbeit.‚Äú\n",
      "Label: freundlich , Vorhersage: neutral    , Confidence: 0.36\n",
      " 4. ‚ÄûDein Engagement wird sehr gesch√§tzt.‚Äú\n",
      "Label: freundlich , Vorhersage: neutral    , Confidence: 0.35\n",
      " 5. ‚ÄûHerzlichen Gl√ºckwunsch zu deinem gro√üartigen Erfolg!‚Äú\n",
      "Label: freundlich , Vorhersage: neutral    , Confidence: 0.36\n",
      " 6. ‚ÄûKann man preislich bei dir noch was machen? Ich kann dir 2 Rohes Kaninchen f√ºr einen Smaragd geben.‚Äú\n",
      "Label: neutral    , Vorhersage: neutral    , Confidence: 0.35\n",
      " 7. ‚ÄûWie crafte ich eine Diamantspitzhacke?‚Äú\n",
      "Label: neutral    , Vorhersage: neutral    , Confidence: 0.35\n",
      " 8. ‚ÄûDas Wald-Biom hat viele Eichenb√§ume.‚Äú\n",
      "Label: neutral    , Vorhersage: neutral    , Confidence: 0.35\n",
      " 9. ‚ÄûUnsere n√§chste Station ist die Mine zum Erze farmen.‚Äú\n",
      "Label: neutral    , Vorhersage: neutral    , Confidence: 0.34\n",
      "10. ‚ÄûDas Wetter soll morgen bew√∂lkt sein.‚Äú\n",
      "Label: neutral    , Vorhersage: neutral    , Confidence: 0.34\n",
      "11. ‚ÄûWas f√ºr ein Idiot bist du bitte?‚Äú\n",
      "Label: unfreundlich, Vorhersage: neutral    , Confidence: 0.34\n",
      "12. ‚ÄûWillst du stress du Arschloch?‚Äú\n",
      "Label: unfreundlich, Vorhersage: neutral    , Confidence: 0.35\n",
      "13. ‚ÄûHey du Arschloch, was kostet eine d√§mliche Karte bei dir?‚Äú\n",
      "Label: unfreundlich, Vorhersage: neutral    , Confidence: 0.35\n",
      "14. ‚ÄûHalte endlich dein Maul.‚Äú\n",
      "Label: unfreundlich, Vorhersage: neutral    , Confidence: 0.35\n",
      "15. ‚ÄûKomm raus ich hau dich!‚Äú\n",
      "Label: unfreundlich, Vorhersage: neutral    , Confidence: 0.36\n",
      "16. ‚ÄûDu Spast, wie ist das Wetter?‚Äú\n",
      "Label: unfreundlich, Vorhersage: neutral    , Confidence: 0.34\n",
      "\n",
      "Gesamtbewertung:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "unfreundlich       0.00      0.00      0.00         6\n",
      "     neutral       0.31      1.00      0.48         5\n",
      "  freundlich       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.31        16\n",
      "   macro avg       0.10      0.33      0.16        16\n",
      "weighted avg       0.10      0.31      0.15        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(MODEL_NAME, \"Original_TinyBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cfc1be4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: Finetuned_TinyBERT\n",
      "\n",
      "Einzelne Predictions:\n",
      " 1. ‚ÄûDu bist so toll und hilfst mir immer!‚Äú\n",
      "Label: freundlich , Vorhersage: freundlich , Confidence: 0.99\n",
      " 2. ‚ÄûHallo lieber Dorfbewohner, k√∂nnte man preislich bei dir noch was machen? Ich kann dir 2 Rohes Kaninchen f√ºr einen Smaragd geben. Das w√§re wirklich freundlich und ich w√ºrde mich echt freuen‚Äú\n",
      "Label: freundlich , Vorhersage: freundlich , Confidence: 0.99\n",
      " 3. ‚ÄûIch freue mich auf unsere Zusammenarbeit.‚Äú\n",
      "Label: freundlich , Vorhersage: freundlich , Confidence: 0.99\n",
      " 4. ‚ÄûDein Engagement wird sehr gesch√§tzt.‚Äú\n",
      "Label: freundlich , Vorhersage: freundlich , Confidence: 0.60\n",
      " 5. ‚ÄûHerzlichen Gl√ºckwunsch zu deinem gro√üartigen Erfolg!‚Äú\n",
      "Label: freundlich , Vorhersage: freundlich , Confidence: 0.99\n",
      " 6. ‚ÄûKann man preislich bei dir noch was machen? Ich kann dir 2 Rohes Kaninchen f√ºr einen Smaragd geben.‚Äú\n",
      "Label: neutral    , Vorhersage: unfreundlich, Confidence: 0.99\n",
      " 7. ‚ÄûWie crafte ich eine Diamantspitzhacke?‚Äú\n",
      "Label: neutral    , Vorhersage: freundlich , Confidence: 0.99\n",
      " 8. ‚ÄûDas Wald-Biom hat viele Eichenb√§ume.‚Äú\n",
      "Label: neutral    , Vorhersage: neutral    , Confidence: 0.77\n",
      " 9. ‚ÄûUnsere n√§chste Station ist die Mine zum Erze farmen.‚Äú\n",
      "Label: neutral    , Vorhersage: neutral    , Confidence: 0.82\n",
      "10. ‚ÄûDas Wetter soll morgen bew√∂lkt sein.‚Äú\n",
      "Label: neutral    , Vorhersage: unfreundlich, Confidence: 0.90\n",
      "11. ‚ÄûWas f√ºr ein Idiot bist du bitte?‚Äú\n",
      "Label: unfreundlich, Vorhersage: unfreundlich, Confidence: 0.98\n",
      "12. ‚ÄûWillst du stress du Arschloch?‚Äú\n",
      "Label: unfreundlich, Vorhersage: unfreundlich, Confidence: 0.99\n",
      "13. ‚ÄûHey du Arschloch, was kostet eine d√§mliche Karte bei dir?‚Äú\n",
      "Label: unfreundlich, Vorhersage: unfreundlich, Confidence: 1.00\n",
      "14. ‚ÄûHalte endlich dein Maul.‚Äú\n",
      "Label: unfreundlich, Vorhersage: unfreundlich, Confidence: 0.99\n",
      "15. ‚ÄûKomm raus ich hau dich!‚Äú\n",
      "Label: unfreundlich, Vorhersage: unfreundlich, Confidence: 0.95\n",
      "16. ‚ÄûDu Spast, wie ist das Wetter?‚Äú\n",
      "Label: unfreundlich, Vorhersage: unfreundlich, Confidence: 0.99\n",
      "\n",
      "Gesamtbewertung:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "unfreundlich       0.75      1.00      0.86         6\n",
      "     neutral       1.00      0.40      0.57         5\n",
      "  freundlich       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.86      0.80      0.78        16\n",
      "weighted avg       0.85      0.81      0.78        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(\"../tinybert-german-finetuned\", \"Finetuned_TinyBERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8e18e",
   "metadata": {},
   "source": [
    "### Im Vergleich der beiden Modelle ist zu erkennen, dass das gefinetunte Modell auf die Test-Daten deutlich besser abschneidet. Die Accuracy steigt von 31 % auf 81 %. Gerade freundliche Formulierungen und unfreundliche S√§tze mit Beleidigungen erkennt das gefinetunte Modell deutlich besser. Zudem ist erkennbar, dass der Confidence-Score mit dem ein Label vohergesagt wird enorm gestiegen ist. Das urspr√ºngliche Modell war sich sehr unsicher was die Predictions angeht, wo hingegen das gefinetunte Modell sehr hohe Confidence Scores erreicht. Dennoch ist kritisch anzmerken, dass das gefinetunte Modell gerade die neutralen S√§tze nicht ganz so gut erkennt. Eine M√∂glcihe L√∂sung w√§re hier evtl. ein gr√∂√üeres Modell zu verwenden, welches sich dann aber nicht mehr auf dem Free-Tier Server hosten lassen w√ºrde. Daher sind wir sehr zufrieden mit den Ergebnissen des gefinetunten Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d3c1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
