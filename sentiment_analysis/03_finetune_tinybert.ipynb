{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a44d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502f84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) CSV laden und splitten\n",
    "#    (90% Training, 10% Validation)\n",
    "ds = load_dataset(\"csv\", data_files=\"sentences_cleaned.csv\", split=\"train\")\n",
    "ds = ds.train_test_split(test_size=0.2, seed=42)\n",
    "train_ds, eval_ds = ds[\"train\"], ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6333f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Labels mappen und Originalspalte droppen\n",
    "label_list = [\"unfreundlich\",\"neutral\",\"freundlich\"]\n",
    "label2id   = {lab:i for i,lab in enumerate(label_list)}\n",
    "id2label   = {i:lab for lab,i in label2id.items()}\n",
    "\n",
    "def map_labels(ex):\n",
    "    return {\"labels\": label2id[ex[\"label\"]]}\n",
    "\n",
    "train_ds = train_ds.map(map_labels, remove_columns=[\"label\"])\n",
    "eval_ds  = eval_ds.map(map_labels, remove_columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b807bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Tokenizer laden und Texte tokenizen (und \"sentence\" entfernen)\n",
    "MODEL_NAME = \"dvm1983/TinyBERT_General_4L_312D_de\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "def tokenize_fn(ex):\n",
    "    return tokenizer(\n",
    "        ex[\"sentence\"], padding=\"max_length\", truncation=True, max_length=128\n",
    "    )\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[\"sentence\"])\n",
    "eval_ds  = eval_ds.map(tokenize_fn, batched=True, remove_columns=[\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2904adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Data collator fÃ¼r dynamisches Padding\n",
    "#    stellt sicher, dass alle Batches rechteckige Tensors sind\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6776d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Format fÃ¼r PyTorch-Tensors\n",
    "train_ds.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "eval_ds.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c579518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dvm1983/TinyBERT_General_4L_312D_de and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 6) Modell laden (Classification Head wird neu initialisiert)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(label_list),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86fa462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1560: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 7) TrainingArguments konfigurieren\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.05,\n",
    "    warmup_ratio=0.2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=250,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=250,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    report_to=[\"none\"],        # keine externen Logger\n",
    "    dataloader_num_workers=0,    # kein Multiprocessing in DataLoader\n",
    "    no_cuda=True,                # CPU-only (MPS/GPU umgehen)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d00902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Metrics-Funktion: entpacke evtl. Tuple in p.predictions\n",
    "def compute_metrics(p):\n",
    "    logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds  = np.argmax(logits, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(p.label_ids, preds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3008d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Trainer initialisieren\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c69675c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-Shapes: {'labels': torch.Size([16]), 'input_ids': torch.Size([16, 128]), 'attention_mask': torch.Size([16, 128])}\n"
     ]
    }
   ],
   "source": [
    "# 10) Optional: Ein Batch-Shape-Debug ausgeben\n",
    "batch = next(iter(trainer.get_train_dataloader()))\n",
    "print(\"Batch-Shapes:\", {k: v.shape for k,v in batch.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2deeb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1377d7a3ff2f4c808234063da89579d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1758 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ce2692b3974d1b83b0504c3e12ef12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4258507192134857, 'eval_accuracy': 0.9397693293464332, 'eval_runtime': 105.0811, 'eval_samples_per_second': 22.278, 'eval_steps_per_second': 0.704, 'epoch': 0.43}\n",
      "{'loss': 0.5812, 'grad_norm': 5.0923991203308105, 'learning_rate': 1.7894736842105264e-05, 'epoch': 0.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a5e32ed1b442a993aee21e6b9d2b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11504026502370834, 'eval_accuracy': 0.9773601025202905, 'eval_runtime': 102.0835, 'eval_samples_per_second': 22.932, 'eval_steps_per_second': 0.725, 'epoch': 0.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653834935f08416c9849751678676c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06530832499265671, 'eval_accuracy': 0.9850491243058522, 'eval_runtime': 95.9329, 'eval_samples_per_second': 24.402, 'eval_steps_per_second': 0.771, 'epoch': 1.28}\n",
      "{'loss': 0.0777, 'grad_norm': 29.406478881835938, 'learning_rate': 1.0782361308677099e-05, 'epoch': 1.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae1511cc48c4482b668fde00f0f2951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0502033568918705, 'eval_accuracy': 0.9884664673216574, 'eval_runtime': 105.8039, 'eval_samples_per_second': 22.126, 'eval_steps_per_second': 0.699, 'epoch': 1.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f38a28b26b4c97ab4cdb62be810f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04191646724939346, 'eval_accuracy': 0.9910294745835113, 'eval_runtime': 109.9916, 'eval_samples_per_second': 21.283, 'eval_steps_per_second': 0.673, 'epoch': 2.13}\n",
      "{'loss': 0.045, 'grad_norm': 0.11010090261697769, 'learning_rate': 3.669985775248933e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7167444145874a0898d52d790e31c541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04453492537140846, 'eval_accuracy': 0.9897479709525844, 'eval_runtime': 102.5108, 'eval_samples_per_second': 22.837, 'eval_steps_per_second': 0.722, 'epoch': 2.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08010a83f4a4a669897492666abbd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03899088874459267, 'eval_accuracy': 0.9918838103374626, 'eval_runtime': 98.2029, 'eval_samples_per_second': 23.838, 'eval_steps_per_second': 0.754, 'epoch': 2.99}\n",
      "{'train_runtime': 1272.5217, 'train_samples_per_second': 22.069, 'train_steps_per_second': 1.382, 'train_loss': 0.20711825677830475, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1758, training_loss=0.20711825677830475, metrics={'train_runtime': 1272.5217, 'train_samples_per_second': 22.069, 'train_steps_per_second': 1.382, 'total_flos': 100677258443520.0, 'train_loss': 0.20711825677830475, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11) Training starten\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d4c7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fertig! Modell liegt in ./tinybert-german-finetuned\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"tinybert-german-finetuned\")\n",
    "print(\"Fertig! Modell liegt in ./tinybert-german-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03b56ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200bfcc5188b4d01b0266c3514e4d534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37902ec61a824a868a73ff227607211e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation: Original_TinyBERT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dvm1983/TinyBERT_General_4L_312D_de and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Einzelne Predictions:\n",
      " 1. â€žDu bist so toll und hilfst mir immer!â€œ\n",
      "     â†’ True: freundlich  (2),  Pred: unfreundlich (0),  Conf: 0.37\n",
      " 2. â€žHallo lieber Dorfbewohner, kÃ¶nnte man preislich bei dir noch was machen? Ich kann dir 2 Rohes Kaninchen fÃ¼r einen Smaragd geben. Das wÃ¤re wirklich freundlich und ich wÃ¼rde mich echt freuenâ€œ\n",
      "     â†’ True: freundlich  (2),  Pred: unfreundlich (0),  Conf: 0.36\n",
      " 3. â€žIch freue mich auf unsere Zusammenarbeit.â€œ\n",
      "     â†’ True: freundlich  (2),  Pred: unfreundlich (0),  Conf: 0.38\n",
      " 4. â€žDein Engagement wird sehr geschÃ¤tzt.â€œ\n",
      "     â†’ True: freundlich  (2),  Pred: unfreundlich (0),  Conf: 0.40\n",
      " 5. â€žHerzlichen GlÃ¼ckwunsch zu deinem groÃŸartigen Erfolg!â€œ\n",
      "     â†’ True: freundlich  (2),  Pred: unfreundlich (0),  Conf: 0.38\n",
      " 6. â€žKann man preislich bei dir noch was machen? Ich kann dir 2 Rohes Kaninchen fÃ¼r einen Smaragd geben.â€œ\n",
      "     â†’ True: neutral     (1),  Pred: unfreundlich (0),  Conf: 0.36\n",
      " 7. â€žBitte sende mir bis Freitag den Abschlussbericht.â€œ\n",
      "     â†’ True: neutral     (1),  Pred: unfreundlich (0),  Conf: 0.38\n",
      " 8. â€žDie Datei findest du im Anhang der E-Mail.â€œ\n",
      "     â†’ True: neutral     (1),  Pred: unfreundlich (0),  Conf: 0.39\n",
      " 9. â€žUnsere nÃ¤chste Station ist der Hauptbahnhof.â€œ\n",
      "     â†’ True: neutral     (1),  Pred: unfreundlich (0),  Conf: 0.38\n",
      "10. â€žDas Wetter soll morgen regenfrei bleiben.â€œ\n",
      "     â†’ True: neutral     (1),  Pred: unfreundlich (0),  Conf: 0.37\n",
      "11. â€žWas fÃ¼r ein Idiot bist du bitte?â€œ\n",
      "     â†’ True: unfreundlich (0),  Pred: unfreundlich (0),  Conf: 0.38\n",
      "12. â€žWillst du stress du Arschloch?â€œ\n",
      "     â†’ True: unfreundlich (0),  Pred: unfreundlich (0),  Conf: 0.38\n",
      "13. â€žHey du arschloch, was kostet eine dÃ¤mliche Karte bei dir?â€œ\n",
      "     â†’ True: unfreundlich (0),  Pred: unfreundlich (0),  Conf: 0.37\n",
      "14. â€žHalte dein Maul halt mal, ja?â€œ\n",
      "     â†’ True: unfreundlich (0),  Pred: unfreundlich (0),  Conf: 0.38\n",
      "15. â€žKomm raus ich hau dich!â€œ\n",
      "     â†’ True: unfreundlich (0),  Pred: unfreundlich (0),  Conf: 0.38\n",
      "16. â€žDu Spast, wie ist das Wetter?â€œ\n",
      "     â†’ True: unfreundlich (0),  Pred: unfreundlich (0),  Conf: 0.38\n",
      "\n",
      "Gesamtbewertung:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "unfreundlich       0.38      1.00      0.55         6\n",
      "     neutral       0.00      0.00      0.00         5\n",
      "  freundlich       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.38        16\n",
      "   macro avg       0.12      0.33      0.18        16\n",
      "weighted avg       0.14      0.38      0.20        16\n",
      "\n",
      "\n",
      "--- Evaluation: Finetuned_TinyBERT ---\n",
      "\n",
      "Einzelne Predictions:\n",
      " 1. â€žDu bist so toll und hilfst mir immer!â€œ\n",
      "     â†’ True: freundlich  (2),  Pred: freundlich  (2),  Conf: 0.99\n",
      " 2. â€žHallo lieber Dorfbewohner, kÃ¶nnte man preislich bei dir noch was machen? Ich kann dir 2 Rohes Kaninchen fÃ¼r einen Smaragd geben. Das wÃ¤re wirklich freundlich und ich wÃ¼rde mich echt freuenâ€œ\n",
      "     â†’ True: freundlich  (2),  Pred: freundlich  (2),  Conf: 0.99\n",
      " 3. â€žIch freue mich auf unsere Zusammenarbeit.â€œ\n",
      "     â†’ True: freundlich  (2),  Pred: freundlich  (2),  Conf: 0.99\n",
      " 4. â€žDein Engagement wird sehr geschÃ¤tzt.â€œ\n",
      "     â†’ True: freundlich  (2),  Pred: freundlich  (2),  Conf: 0.60\n",
      " 5. â€žHerzlichen GlÃ¼ckwunsch zu deinem groÃŸartigen Erfolg!â€œ\n",
      "     â†’ True: freundlich  (2),  Pred: freundlich  (2),  Conf: 0.99\n",
      " 6. â€žKann man preislich bei dir noch was machen? Ich kann dir 2 Rohes Kaninchen fÃ¼r einen Smaragd geben.â€œ\n",
      "     â†’ True: neutral     (1),  Pred: unfreundlich (0),  Conf: 0.99\n",
      " 7. â€žBitte sende mir bis Freitag den Abschlussbericht.â€œ\n",
      "     â†’ True: neutral     (1),  Pred: freundlich  (2),  Conf: 0.99\n",
      " 8. â€žDie Datei findest du im Anhang der E-Mail.â€œ\n",
      "     â†’ True: neutral     (1),  Pred: neutral     (1),  Conf: 0.77\n",
      " 9. â€žUnsere nÃ¤chste Station ist der Hauptbahnhof.â€œ\n",
      "     â†’ True: neutral     (1),  Pred: neutral     (1),  Conf: 0.82\n",
      "10. â€žDas Wetter soll morgen regenfrei bleiben.â€œ\n",
      "     â†’ True: neutral     (1),  Pred: unfreundlich (0),  Conf: 0.90\n",
      "11. â€žWas fÃ¼r ein Idiot bist du bitte?â€œ\n",
      "     â†’ True: unfreundlich (0),  Pred: unfreundlich (0),  Conf: 0.98\n",
      "12. â€žWillst du stress du Arschloch?â€œ\n",
      "     â†’ True: unfreundlich (0),  Pred: unfreundlich (0),  Conf: 0.99\n",
      "13. â€žHey du arschloch, was kostet eine dÃ¤mliche Karte bei dir?â€œ\n",
      "     â†’ True: unfreundlich (0),  Pred: unfreundlich (0),  Conf: 1.00\n",
      "14. â€žHalte dein Maul halt mal, ja?â€œ\n",
      "     â†’ True: unfreundlich (0),  Pred: neutral     (1),  Conf: 0.92\n",
      "15. â€žKomm raus ich hau dich!â€œ\n",
      "     â†’ True: unfreundlich (0),  Pred: unfreundlich (0),  Conf: 0.95\n",
      "16. â€žDu Spast, wie ist das Wetter?â€œ\n",
      "     â†’ True: unfreundlich (0),  Pred: unfreundlich (0),  Conf: 0.99\n",
      "\n",
      "Gesamtbewertung:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "unfreundlich       0.71      0.83      0.77         6\n",
      "     neutral       0.67      0.40      0.50         5\n",
      "  freundlich       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.75        16\n",
      "   macro avg       0.74      0.74      0.73        16\n",
      "weighted avg       0.74      0.75      0.73        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.special import softmax\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1) Test-Set definieren\n",
    "# 1) Test-Set definieren (erweitert)\n",
    "test_data = [\n",
    "    # freundlich\n",
    "    {\"sentence\": \"Du bist so toll und hilfst mir immer!\",               \"label\": \"freundlich\"},\n",
    "    {\"sentence\": \"Hallo lieber Dorfbewohner, kÃ¶nnte man preislich bei dir noch was machen? Ich kann dir 2 Rohes Kaninchen fÃ¼r einen Smaragd geben. Das wÃ¤re wirklich freundlich und ich wÃ¼rde mich echt freuen\",        \"label\": \"freundlich\"},\n",
    "    {\"sentence\": \"Ich freue mich auf unsere Zusammenarbeit.\",          \"label\": \"freundlich\"},\n",
    "    {\"sentence\": \"Dein Engagement wird sehr geschÃ¤tzt.\",              \"label\": \"freundlich\"},\n",
    "    {\"sentence\": \"Herzlichen GlÃ¼ckwunsch zu deinem groÃŸartigen Erfolg!\", \"label\": \"freundlich\"},\n",
    "\n",
    "    # neutral\n",
    "    {\"sentence\": \"Kann man preislich bei dir noch was machen? Ich kann dir 2 Rohes Kaninchen fÃ¼r einen Smaragd geben.\",           \"label\": \"neutral\"},\n",
    "    {\"sentence\": \"Bitte sende mir bis Freitag den Abschlussbericht.\",  \"label\": \"neutral\"},\n",
    "    {\"sentence\": \"Die Datei findest du im Anhang der E-Mail.\",         \"label\": \"neutral\"},\n",
    "    {\"sentence\": \"Unsere nÃ¤chste Station ist der Hauptbahnhof.\",       \"label\": \"neutral\"},\n",
    "    {\"sentence\": \"Das Wetter soll morgen regenfrei bleiben.\",          \"label\": \"neutral\"},\n",
    "\n",
    "    # unfreundlich\n",
    "    {\"sentence\": \"Was fÃ¼r ein Idiot bist du bitte?\",                   \"label\": \"unfreundlich\"},\n",
    "    {\"sentence\": \"Willst du stress du Arschloch?\",          \"label\": \"unfreundlich\"},\n",
    "    {\"sentence\": \"Hey du arschloch, was kostet eine dÃ¤mliche Karte bei dir?\",                  \"label\": \"unfreundlich\"},\n",
    "    {\"sentence\": \"Halte dein Maul halt mal, ja?\",                \"label\": \"unfreundlich\"},\n",
    "    {\"sentence\": \"Komm raus ich hau dich!\",   \"label\": \"unfreundlich\"},\n",
    "    {\"sentence\": \"Du Spast, wie ist das Wetter?\",                \"label\": \"unfreundlich\"},\n",
    "]\n",
    "\n",
    "label_list = [\"unfreundlich\", \"neutral\", \"freundlich\"]\n",
    "label2id   = {lab:i for i,lab in enumerate(label_list)}\n",
    "id2label   = {i:lab for lab,i in label2id.items()}\n",
    "\n",
    "# 2) Dataset erzeugen und Labels mappen\n",
    "test_ds = Dataset.from_list(test_data)\n",
    "test_ds = test_ds.map(lambda ex: {\"labels\": label2id[ex[\"label\"]]}, remove_columns=[\"label\"])\n",
    "\n",
    "# 3) Tokenizer & Tokenisierung\n",
    "MODEL_NAME = \"dvm1983/TinyBERT_General_4L_312D_de\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "def tokenize_fn(ex):\n",
    "    return tokenizer(ex[\"sentence\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "test_ds = test_ds.map(tokenize_fn, batched=True, remove_columns=[\"sentence\"])\n",
    "test_ds.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "\n",
    "# 4) Data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# 5) compute_metrics: nur Accuracy\n",
    "def compute_metrics(p):\n",
    "    logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds  = np.argmax(logits, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(p.label_ids, preds)}\n",
    "\n",
    "# 6) Evaluierungs-Funktion\n",
    "def evaluate_model(model_path: str, name: str):\n",
    "    print(f\"\\n--- Evaluation: {name} ---\")\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Modell laden\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_path,\n",
    "        num_labels=len(label_list),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    ).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Dataloader\n",
    "    test_loader = DataLoader(test_ds, batch_size=16)\n",
    "\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            preds = torch.argmax(probs, dim=-1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Originaldaten fÃ¼r Anzeige\n",
    "    sentences = [ex[\"sentence\"] for ex in test_data]\n",
    "\n",
    "    # Anzeige\n",
    "    print(\"\\nEinzelne Predictions:\")\n",
    "    for i, (sent, true_id, pred_id, prob_row) in enumerate(zip(sentences, all_labels, all_preds, all_probs)):\n",
    "        print(f\"{i+1:2d}. â€ž{sent}â€œ\")\n",
    "        print(f\"     â†’ True: {id2label[true_id]:11s} ({true_id}),\"\n",
    "              f\"  Pred: {id2label[pred_id]:11s} ({pred_id}),\"\n",
    "              f\"  Conf: {prob_row[pred_id]:.2f}\")\n",
    "\n",
    "    # Gesamtbewertung\n",
    "    print(\"\\nGesamtbewertung:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=label_list))\n",
    "\n",
    "# 7) Vergleich\n",
    "evaluate_model(MODEL_NAME, \"Original_TinyBERT\")\n",
    "evaluate_model(\"../tinybert-german-finetuned\", \"Finetuned_TinyBERT\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f33cbf7",
   "metadata": {},
   "source": [
    "### Model zu Onnx konvertieren, damit es in Javascript eingebunden werden kann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7898879e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnxruntime in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.21.1)\n",
      "Requirement already satisfied: optimum[exporters] in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.24.0)\n",
      "Requirement already satisfied: transformers>=4.29 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optimum[exporters]) (4.45.2)\n",
      "Requirement already satisfied: torch>=1.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optimum[exporters]) (2.0.1)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optimum[exporters]) (23.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optimum[exporters]) (1.26.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optimum[exporters]) (0.26.1)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optimum[exporters]) (1.14.1)\n",
      "Requirement already satisfied: timm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from optimum[exporters]) (1.0.15)\n",
      "Requirement already satisfied: coloredlogs in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from onnxruntime) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from onnxruntime) (4.24.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from onnxruntime) (1.12)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum[exporters]) (3.12.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum[exporters]) (2024.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum[exporters]) (6.0.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum[exporters]) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum[exporters]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum[exporters]) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.11->optimum[exporters]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.11->optimum[exporters]) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers>=4.29->optimum[exporters]) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers>=4.29->optimum[exporters]) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers>=4.29->optimum[exporters]) (0.20.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from timm->optimum[exporters]) (0.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=1.11->optimum[exporters]) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.8.0->optimum[exporters]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.8.0->optimum[exporters]) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.8.0->optimum[exporters]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.8.0->optimum[exporters]) (2022.12.7)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision->timm->optimum[exporters]) (10.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"optimum[exporters]\" onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "534d6497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir -p tinybert-german-finetuned/onnx\n",
    "optimum-cli export onnx \\\n",
    "  --model tinybert-german-finetuned \\\n",
    "  --task sequence-classification \\\n",
    "  tinybert-german-finetuned/onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416fcf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
